{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: no se puede crear el directorio «build»: El archivo ya existe\n",
      "-- The C compiler identification is GNU 8.3.0\n",
      "-- The CXX compiler identification is GNU 8.3.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "Release mode\n",
      "-- Found PythonInterp: /usr/bin/python (found version \"2.7.16\") \n",
      "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython2.7.so\n",
      "-- pybind11 v2.3.dev0\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- LTO enabled\n",
      "CMAKE_INSTALL_PREFIX=/home/guidotripodi/Documentos/Facu/MN/mntp2/mnv-tp2\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/guidotripodi/Documentos/Facu/MN/mntp2/mnv-tp2/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target tp2_pybind\u001b[0m\n",
      "[  6%] \u001b[32mBuilding CXX object CMakeFiles/tp2_pybind.dir/src/main_pybind.cpp.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/tp2_pybind.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/tp2_pybind.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/tp2_pybind.dir/src/eigen.cpp.o\u001b[0m\n",
      "[ 33%] \u001b[32m\u001b[1mLinking CXX executable tp2_pybind\u001b[0m\n",
      "[ 33%] Built target tp2_pybind\n",
      "\u001b[35m\u001b[1mScanning dependencies of target sentiment\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/sentiment.cpp.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/eigen.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32m\u001b[1mLinking CXX shared module sentiment.so\u001b[0m\n",
      "[ 66%] Built target sentiment\n",
      "\u001b[35m\u001b[1mScanning dependencies of target tp2\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/main.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 93%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/eigen.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable tp2\u001b[0m\n",
      "[100%] Built target tp2\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "-- Installing: /home/guidotripodi/Documentos/Facu/MN/mntp2/mnv-tp2/notebooks/sentiment.so\n"
     ]
    }
   ],
   "source": [
    "!cd .. && git submodule init\n",
    "!cd .. && git submodule update\n",
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!cd ../build && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../build && make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: *.tgz: No se puede efectuar open: No existe el archivo o el directorio\n",
      "tar: Error is not recoverable: exiting now\n",
      "Cantidad de documentos: 12500\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "!cd ../data && tar -xvf *.tgz\n",
    "\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "print(\"Cantidad de documentos: {}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias de entrenamiento = 6225\n",
      "Cantidad de instancias de test = 6275\n"
     ]
    }
   ],
   "source": [
    "text_train = df[df.type == 'train'][\"review\"]\n",
    "label_train = df[df.type == 'train'][\"label\"]\n",
    "\n",
    "text_test = df[df.type == 'test'][\"review\"]\n",
    "label_test = df[df.type == 'test'][\"label\"]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "\n",
    "vectorizer.fit(text_train)\n",
    "\n",
    "X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento KNN SIN PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 1 :  acc 0.5499601593625498\n",
      "k 5 :  acc 0.5915537848605578\n",
      "k 10 :  acc 0.6065338645418327\n",
      "k 15 :  acc 0.6237450199203187\n",
      "k 20 :  acc 0.6341035856573706\n",
      "k 25 :  acc 0.6341035856573706\n",
      "k 50 :  acc 0.6473306772908366\n",
      "k 100 :  acc 0.6388844621513944\n",
      "k 150 :  acc 0.6283665338645419\n",
      "k 200 :  acc 0.6224701195219123\n",
      "k 250 :  acc 0.6224701195219123\n",
      "k 300 :  acc 0.6167330677290837\n",
      "k 350 :  acc 0.6162549800796813\n",
      "[0.5499601593625498, 0.5915537848605578, 0.6065338645418327, 0.6237450199203187, 0.6341035856573706, 0.6341035856573706, 0.6473306772908366, 0.6388844621513944, 0.6283665338645419, 0.6224701195219123, 0.6224701195219123, 0.6167330677290837, 0.6162549800796813]\n"
     ]
    }
   ],
   "source": [
    "import sentiment\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scores = []\n",
    "k_values = [1,5,10,15,20,25,50] + list(range(100,400,50))\n",
    "\n",
    "for k in k_values:\n",
    "\n",
    "    clf = sentiment.KNNClassifier(k)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"k: {}   acc: {}\".format(k, acc))\n",
    "    scores.append(acc)\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento KNN variando max y min df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 50   acc: 0.6643824701195219 maxDF: 0.8 minDF: 0.01\n",
      "k: 50   acc: 0.6624701195219124 maxDF: 0.8 minDF: 0.02\n",
      "k: 50   acc: 0.6616733067729084 maxDF: 0.8 minDF: 0.03\n",
      "k: 50   acc: 0.6661354581673307 maxDF: 0.8 minDF: 0.05\n",
      "k: 50   acc: 0.6541832669322709 maxDF: 0.8 minDF: 0.08\n",
      "k: 50   acc: 0.6567330677290837 maxDF: 0.8 minDF: 0.1\n",
      "k: 50   acc: 0.6621513944223107 maxDF: 0.85 minDF: 0.01\n",
      "k: 50   acc: 0.6613545816733067 maxDF: 0.85 minDF: 0.02\n",
      "k: 50   acc: 0.660398406374502 maxDF: 0.85 minDF: 0.03\n",
      "k: 50   acc: 0.6599203187250996 maxDF: 0.85 minDF: 0.05\n",
      "k: 50   acc: 0.6535458167330678 maxDF: 0.85 minDF: 0.08\n",
      "k: 50   acc: 0.6513147410358566 maxDF: 0.85 minDF: 0.1\n",
      "k: 50   acc: 0.6473306772908366 maxDF: 0.9 minDF: 0.01\n",
      "k: 50   acc: 0.6438247011952192 maxDF: 0.9 minDF: 0.02\n",
      "k: 50   acc: 0.6441434262948207 maxDF: 0.9 minDF: 0.03\n",
      "k: 50   acc: 0.6334661354581673 maxDF: 0.9 minDF: 0.05\n",
      "k: 50   acc: 0.6326693227091633 maxDF: 0.9 minDF: 0.08\n",
      "k: 50   acc: 0.6310756972111554 maxDF: 0.9 minDF: 0.1\n",
      "k: 50   acc: 0.6532270916334662 maxDF: 0.92 minDF: 0.01\n",
      "k: 50   acc: 0.6522709163346614 maxDF: 0.92 minDF: 0.02\n",
      "k: 50   acc: 0.6533864541832669 maxDF: 0.92 minDF: 0.03\n",
      "k: 50   acc: 0.6466932270916335 maxDF: 0.92 minDF: 0.05\n",
      "k: 50   acc: 0.6438247011952192 maxDF: 0.92 minDF: 0.08\n",
      "k: 50   acc: 0.6387250996015936 maxDF: 0.92 minDF: 0.1\n",
      "k: 50   acc: 0.6458964143426295 maxDF: 0.95 minDF: 0.01\n",
      "k: 50   acc: 0.6452589641434263 maxDF: 0.95 minDF: 0.02\n",
      "k: 50   acc: 0.6403187250996016 maxDF: 0.95 minDF: 0.03\n",
      "k: 50   acc: 0.6438247011952192 maxDF: 0.95 minDF: 0.05\n",
      "k: 50   acc: 0.6352191235059761 maxDF: 0.95 minDF: 0.08\n",
      "k: 50   acc: 0.6312350597609562 maxDF: 0.95 minDF: 0.1\n",
      "k: 50   acc: 0.6420717131474104 maxDF: 1.0 minDF: 0.01\n",
      "k: 50   acc: 0.6385657370517929 maxDF: 1.0 minDF: 0.02\n",
      "k: 50   acc: 0.6379282868525896 maxDF: 1.0 minDF: 0.03\n",
      "k: 50   acc: 0.633784860557769 maxDF: 1.0 minDF: 0.05\n",
      "k: 50   acc: 0.6313944223107569 maxDF: 1.0 minDF: 0.08\n",
      "k: 50   acc: 0.6350597609561753 maxDF: 1.0 minDF: 0.1\n",
      "[0.6350597609561753]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sentiment\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "maxDF_values = [0.80,0.85,0.90,0.92,0.95,1.00]\n",
    "minDF_values = [0.01,0.02,0.03,0.05,0.08,0.10]\n",
    "\n",
    "for maxDF in maxDF_values:\n",
    "    \n",
    "    for minDF in minDF_values:\n",
    "        \n",
    "        vectorizer = CountVectorizer(max_df=maxDF, min_df=minDF, max_features=5000)\n",
    "\n",
    "        vectorizer.fit(text_train)\n",
    "\n",
    "        X_train1, y_train1 = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "        X_test1, y_test1 = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "\n",
    "        scores = []\n",
    "        k_values = [50]\n",
    "\n",
    "        for k in k_values:\n",
    "            clf = sentiment.KNNClassifier(k)\n",
    "            clf.fit(X_train1, y_train1)\n",
    "            y_pred1 = clf.predict(X_test1)\n",
    "            acc = accuracy_score(y_test1, y_pred1)\n",
    "            print(\"k: {}   acc: {} maxDF: {} minDF: {}\".format(k, acc,maxDF, minDF))\n",
    "            scores.append(acc)\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento KNN CON PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1  acc: 0.5062948207171315 Alpha: 50 \n",
      "k: 5  acc: 0.49338645418326693 Alpha: 50 \n",
      "k: 10  acc: 0.49673306772908365 Alpha: 50 \n",
      "k: 15  acc: 0.5064541832669323 Alpha: 50 \n",
      "k: 20  acc: 0.5064541832669323 Alpha: 50 \n",
      "k: 25  acc: 0.5064541832669323 Alpha: 50 \n",
      "k: 50  acc: 0.5064541832669323 Alpha: 50 \n",
      "k: 100  acc: 0.5064541832669323 Alpha: 50 \n",
      "k: 150  acc: 0.49354581673306774 Alpha: 50 \n",
      "k: 200  acc: 0.49354581673306774 Alpha: 50 \n",
      "k: 250  acc: 0.49354581673306774 Alpha: 50 \n",
      "k: 300  acc: 0.49354581673306774 Alpha: 50 \n",
      "k: 350  acc: 0.49354581673306774 Alpha: 50 \n",
      "k: 1  acc: 0.49354581673306774 Alpha: 100 \n",
      "k: 5  acc: 0.5064541832669323 Alpha: 100 \n",
      "k: 10  acc: 0.5064541832669323 Alpha: 100 \n",
      "k: 15  acc: 0.5064541832669323 Alpha: 100 \n",
      "k: 20  acc: 0.5064541832669323 Alpha: 100 \n",
      "k: 25  acc: 0.5064541832669323 Alpha: 100 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1760b0325a0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2aux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0my_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"k: {}  acc: {} Alpha: {} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sentiment\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.85, min_df=0.01, max_features=5000)\n",
    "\n",
    "vectorizer.fit(text_train)\n",
    "\n",
    "X_train2, y_train2 = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test2, y_test2 = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "\n",
    "scores = []\n",
    "k_values = [1,5,10,15,20,25,50] + list(range(100,400,50))\n",
    "alpha_values = [50,100,150]\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    for k in k_values:\n",
    "        X_train2aux = X_train2\n",
    "        pca = sentiment.PCA(alpha)\n",
    "        pca.fit(X_train2aux.toarray())\n",
    "        \n",
    "        X_train2aux = pca.transform(X_train2aux)\n",
    "        X_test2 = pca.transform(X_test2)\n",
    "        \n",
    "        clf = sentiment.KNNClassifier(k)\n",
    "        clf.fit(X_train2aux, y_train2)\n",
    "        \n",
    "        y_pred2 = clf.predict(X_test2)\n",
    "        acc = accuracy_score(y_test2, y_pred2)\n",
    "        print(\"k: {}  acc: {} Alpha: {} \".format(k, acc, alpha))\n",
    "        scores.append(acc)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variando cantidad de instancias de entrenamiento KNN SIN PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sentiment\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.85, min_df=0.01, max_features=5000)\n",
    "\n",
    "vectorizer.fit(text_train)\n",
    "\n",
    "X_train3, y_train3 = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test3, y_test3 = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "\n",
    "x_values = [5,10,20,50,100,500,1000,2000,3000,4000,5000,6500]\n",
    "\n",
    "scores = []\n",
    "k_values = [1,5,10,15,20,25,50] + list(range(100,400,50))\n",
    "\n",
    "for x in x_values:\n",
    "    \n",
    "    X_train3 = X_train3[0:x]\n",
    "    y_train3 = y_train3[0:x]\n",
    "        \n",
    "    for k in k_values:\n",
    "\n",
    "        clf = sentiment.KNNClassifier(k)\n",
    "\n",
    "        clf.fit(X_train3, y_train3)\n",
    "\n",
    "        y_pred3 = clf.predict(X_test3)\n",
    "\n",
    "        acc = accuracy_score(y_test3, y_pred3)\n",
    "        print(\"k: {}   acc: {}\".format(k, acc))\n",
    "        scores.append(acc)\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variando cantidad de instancias de entrenamiento KNN CON PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sentiment\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.85, min_df=0.01, max_features=5000)\n",
    "\n",
    "vectorizer.fit(text_train)\n",
    "\n",
    "X_train4, y_train4 = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test4, y_test4 = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "\n",
    "x_values = [5,10,20,50,100,500,1000,2000,3000,4000,5000,6500]\n",
    "\n",
    "scores = []\n",
    "k_values = [1,5,10,15,20,25,50] + list(range(100,400,50))\n",
    "alpha_values = [50,100,150]\n",
    "for x in x_values:\n",
    "    \n",
    "    X_train4 = X_train4[0:x]\n",
    "    y_train4 = y_train4[0:x]\n",
    "    for alpha in alpha_values:\n",
    "        for k in k_values:\n",
    "            X_train4aux = X_train4\n",
    "            pca = sentiment.PCA(alpha)\n",
    "            pca.fit(X_train4aux.toarray())\n",
    "\n",
    "            X_train4aux = pca.transform(X_train4aux)\n",
    "            X_test4 = pca.transform(X_test4)\n",
    "\n",
    "            clf = sentiment.KNNClassifier(k)\n",
    "            clf.fit(X_train4aux, y_train4)\n",
    "\n",
    "            y_pred4 = clf.predict(X_test4)\n",
    "            acc = accuracy_score(y_test4, y_pred4)\n",
    "            print(\"k: {}   acc: {}  Alpha: {}\".format(k, acc, alpha))\n",
    "            scores.append(acc)\n",
    "\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
